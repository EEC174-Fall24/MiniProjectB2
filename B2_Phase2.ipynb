{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Mini-Project B2 Phase 2: Semantic Segmentation on Lung CT Scans**"
      ],
      "metadata": {
        "id": "epciAvR5orOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, you will be segmenting CT scan images of lungs. We will be using a combination of the [LUng Nodule Analysis 2016 (LUNA) Competition dataset](https://luna16.grand-challenge.org/) and [Kaggle Data Science Bowl 2017 dataset](https://www.kaggle.com/c/data-science-bowl-2017).\n",
        "\n",
        "The downloaded dataset can be found here: [Finding and Measuring Lungs in CT Data](https://www.kaggle.com/datasets/kmader/finding-lungs-in-ct-data).\n",
        "\n",
        "**Problem Motivation:** Medical diagnosis and research often rely on the analysis of medical images to identify lesions and anomalies. In the context of lung cancer diagnosis, analyzing CT images is particularly challenging due to the complexity of grayscale medical scans. Accurate segmentation of the lungs is a critical first step in detecting potential abnormalities and improving disease detection.\n",
        "\n",
        "**Lung CT Dataset Samples:**\n",
        "\n",
        "    Number of Samples:\n",
        "    ・266 2D Scans + 266 Corresponding Masks\n",
        "    ・4 3D Scans + 4 Corresponding Masks\n",
        "    ・lung_stats.csv\n",
        "\n",
        "\n",
        "\n",
        "**Lung CT Annotated Data:**\n",
        "\n",
        "\n",
        "\n",
        "Corresponding annotated data is stored in `lung_stats.csv`. We will explore it later in the lab.\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "yCzmb8x6pAAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Finding and Measuring Lungs in CT Dataset**"
      ],
      "metadata": {
        "id": "inmWxlYyscId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "-gWQScmosswj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niQC3I4xn01i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "VsKcoDWqsoJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zRRvLfNVoB7",
        "outputId": "dae9192a-fa3b-43de-f7cc-f2f550c0ea3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5U376TMjn01a"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/Shareddrives/MiniProject-B1/Lung_CT/2d_images'\n",
        "mask_dir = '/content/drive/Shareddrives/MiniProject-B1/Lung_CT/2d_masks'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.1 Dataset Creation**"
      ],
      "metadata": {
        "id": "A--7GC2PtHBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the Lab 3 Phase 3 Stanford Dataset you will need to create your inherit from ```Dataset``` class to load the dataset and overload the ```___init__()```, ```__len__()```, and ```__getitem__()``` functions."
      ],
      "metadata": {
        "id": "dcHRSDE_tzGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdu1Shyun01k"
      },
      "outputs": [],
      "source": [
        "class LungSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (str): Directory with images.\n",
        "            mask_dir (str): Directory with masks.\n",
        "            transform (callable, optional): Transformations for images.\n",
        "            mask_transform (callable, optional): Transformations for masks.\n",
        "        \"\"\"\n",
        "\n",
        "        '''\n",
        "\n",
        "        TODO\n",
        "\n",
        "        '''\n",
        "\n",
        "        return image, mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to Lab 3, we will use augmentations from the [`torchvision.transforms`](https://pytorch.org/vision/0.9/transforms.html) library.\n",
        "\n",
        "You may choose to apply your own augmentations if you wish, but be careful with augmentations that are too strong as it may affect your model performance since the dataset is small."
      ],
      "metadata": {
        "id": "cNeGA4UVs0zI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YibU27Dfn01l"
      },
      "outputs": [],
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),  # Ensure images are large enough for DeepLabV3\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512), interpolation=Image.NEAREST),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en7PsGIUn01m"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# Since the dataset is small and images are large, we will use a small batch size for this lab\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Initialize dataset\n",
        "dataset = LungSegmentationDataset(\n",
        "    image_dir=image_dir,\n",
        "    mask_dir=mask_dir,\n",
        "    transform=image_transform,\n",
        "    mask_transform=mask_transform\n",
        ")\n",
        "\n",
        "# Split dataset into training and validation, decide on split % yourself!\n",
        "train_size = ''' TODO '''\n",
        "val_size = ''' TODO '''\n",
        "train_dataset, val_dataset = random_split(''' TODO ''')\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = ''' TODO '''\n",
        "val_loader = ''' TODO '''\n",
        "\n",
        "# Check the sizes of the splits\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.3 Visualize Dataset**\n",
        "\n",
        "Let's first take a look at the 2D CT Scans and the masks in the datasets before segmentation. Below, display 4 CT images and their corresponding masks.\n",
        "\n",
        "*Note:* This dataset does not contain classes! Dislay any 4 random images."
      ],
      "metadata": {
        "id": "7ToABfGutnPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ictQ9Pbtn01o"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "TODO\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Train Segmentation Model**"
      ],
      "metadata": {
        "id": "mFPmPOPRt8G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will train a deep learning model for lung segmentation using a U-Net architecture with a ResNet34 backbone. This model, widely used in medical image analysis, loads pretrained weights on ImageNet to improve performance and speed up training. Please import the library in the following way below to train your model:\n",
        "\n",
        "Learn more about the [`segmentation_models_pytorch`](https://github.com/qubvel-org/segmentation_models.pytorch) models at the official documentation.\n",
        "\n",
        "```python\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",      # Use a ResNet34 backbone\n",
        "    encoder_weights=\"imagenet\",  # Pretrained on ImageNet\n",
        "    in_channels=3,               # RGB images\n",
        "    classes=1                    # Single-class segmentation (binary mask)\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UXTKFRLFurmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.1 Install and Run Model**"
      ],
      "metadata": {
        "id": "QRmCh9bZwQAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1.1 Install Required Libraries**\n",
        "\n",
        "Before starting, ensure you have the necessary libraries installed:"
      ],
      "metadata": {
        "id": "0mLR4G_uuTsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #!pip install segmentation-models-pytorch\n",
        " import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "BwsmBy-tuSok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1.2 Train Model**\n",
        "\n",
        "Import and load your model, then train the model for between 5 to 10 epochs.\n",
        "\n",
        "Please print the epoch and training loss per epoch:"
      ],
      "metadata": {
        "id": "SmgITVYDvkG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D9J_wC5n01p"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "TODO\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2 Visualize Model Results**\n",
        "\n",
        "Create a function to pull a random image and visualize results of the model below. Please display:\n",
        "\n",
        "\n",
        "\n",
        "*   Original CT Scan\n",
        "*   Ground Truth Corresponding Mask\n",
        "*   Segmentation Mask Results\n",
        "*   Segmentation Overlay on Original CT Scan\n",
        "\n",
        "Please plot all 4 images together with titles for easy visualization.\n",
        "\n"
      ],
      "metadata": {
        "id": "N4xadQ9UwFy9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mprEaNNgn01r"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def visualize_random_prediction(image_dir, mask_dir, model, transform, device):\n",
        "    \"\"\"\n",
        "    Visualize a random image and mask from the dataset, along with model predictions.\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Path to the directory containing the images.\n",
        "        mask_dir (str): Path to the directory containing the masks.\n",
        "        model: Trained PyTorch model for segmentation.\n",
        "        transform: Transformations to apply to the images before inference.\n",
        "        device: Device (CPU or GPU) to run the model inference on.\n",
        "    \"\"\"\n",
        "\n",
        "    return image, mask, pred_mask, img_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5KA2bWQn01s"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "visualize_random_prediction(image_dir, mask_dir, model, image_transform, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3 Statistical Analysis from Segmentation Masks**\n",
        "\n",
        "Segmentation plays a critical role in the medical field as it allows us to derive valuable information from images automatically. By analyzing segmentation masks, we can extract meaningful statistics that help assess regions of interest, such as lung areas, in CT scans.\n",
        "\n",
        "In this section, you will calculate statistics from segmentation masks and compare predictions with ground truth data to evaluate the accuracy of the model."
      ],
      "metadata": {
        "id": "uQ7hjKmvwzKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hounsfield Unit:**\n",
        "A Hounsfield Unit (HU) is a measure of the density of tissue in a CT scan. It represents how much a tissue attenuates X-rays, with air assigned a value of -1000 HU, water as 0 HU, and bone typically above +1000 HU. For the statistics below, use the pixel intensity values directly from the CT scan, as they are usually already in Hounsfield Units.\n",
        "\n",
        "**Statistics From Segmentation:**\n",
        "\n",
        "* `Lung Area in Pixels (lung_area_px)`:\n",
        "The total number of pixels in the segmentation mask where the lung region is identified.\n",
        "\n",
        "* `Lung Volume Fraction (lung_volume_fraction)`:\n",
        "The fraction of lung pixels compared to the total image pixels. This provides an estimate of the proportion of the image occupied by the lung region.\n",
        "\n",
        "* `Mean Hounsfield Unit (lung_mean_hu)`:\n",
        "The average intensity value (Hounsfield Unit) inside the lung region. This gives a sense of the lung density, which can indicate abnormalities.\n",
        "\n",
        "* `95th Percentile Hounsfield Unit (lung_pd95_hu)`:\n",
        "The value below which 95% of the intensity values in the lung region fall. This statistic can help identify bright regions, such as nodules or lesions.\n",
        "\n",
        "* `5th Percentile Hounsfield Unit (lung_pd05_hu)`:\n",
        "The value below which 5% of the intensity values in the lung region fall. This can help identify dark areas, such as air pockets or hollow spaces."
      ],
      "metadata": {
        "id": "WuMJk9cQwo9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write a Function to Calculate Statistics:**\n",
        "\n",
        "Implement a Python function that calculates the above statistics for a given mask and corresponding CT image. Use the following steps:\n",
        "\n",
        "1. Count the pixels in the mask where the lung is segmented.\n",
        "2. Compute the mean, 95th percentile, and 5th percentile Hounsfield Units for the lung region.\n",
        "3. Return these values as a tuple.\n",
        "\n",
        "**Apply the Function:**\n",
        "\n",
        "- Calculate the statistics for the predicted mask using the `calculate_statistics` function.\n",
        "\n",
        "- Then, calculate the statistics for the ground truth mask using the same function.\n",
        "\n",
        "- Compare the statistics calculated from the predicted mask with the ground truth statistics (from the CSV) and the statistics calculated from the ground truth mask."
      ],
      "metadata": {
        "id": "fF3PDKVdyNUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_wrFSYmn01s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_statistics(mask, ct_slice):\n",
        "    \"\"\"\n",
        "    Calculate statistical metrics from a segmentation mask and corresponding CT slice.\n",
        "\n",
        "    Args:\n",
        "        mask (np.ndarray): Binary segmentation mask (0 for background, 1 for lung).\n",
        "        ct_slice (np.ndarray): CT slice with intensity values (Hounsfield Units).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (lung_area_px, lung_volume_fraction, lung_mean_hu, lung_pd95_hu, lung_pd05_hu)\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "\n",
        "    TODO\n",
        "\n",
        "    '''\n",
        "\n",
        "    return lung_area_px, lung_volume_fraction, lung_mean_hu, lung_pd95_hu, lung_pd05_hu\n",
        "\n",
        "\n",
        "def visualize_stats(image_dir, mask_dir, csv_path, model, transform, mask_transform, device):\n",
        "    \"\"\"\n",
        "    Visualize a random image and mask, predict the segmentation mask, calculate statistics,\n",
        "    and compare the results with the ground truth statistics from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Path to the directory containing the images.\n",
        "        mask_dir (str): Path to the directory containing the masks.\n",
        "        csv_path (str): Path to the CSV file containing ground truth statistics.\n",
        "        model: Trained PyTorch model for segmentation.\n",
        "        transform: Transformations to apply to the images before inference.\n",
        "        mask_transform: Transformations to apply to the mask before calculations.\n",
        "        device: Device (CPU or GPU) to run the model inference on.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "\n",
        "    TODO\n",
        "\n",
        "    '''\n",
        "\n",
        "\n",
        "    return comparison_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhBwGpPln01t"
      },
      "outputs": [],
      "source": [
        "comparison_df = visualize_and_calculate_statistics(''' TODO ''')\n",
        "\n",
        "# Visualize results!\n",
        "comparison_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Report"
      ],
      "metadata": {
        "id": "KxGsa2W-Mbu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the predicted statistics (from the predicted mask) with the ground truth statistics (from the CSV).\n",
        "\n",
        "How close are the predictions to the ground truth?\n",
        "\n",
        "Are there significant differences for specific metrics (e.g., lung area, mean HU)?\n",
        "\n",
        "In your report, answer the above questions and reflect on the data you've collected in your calculated statistics."
      ],
      "metadata": {
        "id": "i1RSBPjdMfXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER HERE"
      ],
      "metadata": {
        "id": "wWIp-pUKNAUI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jq5lg1qDIvy"
      },
      "source": [
        "___\n",
        "___\n",
        "# End of MiniProject B2 Phase 2 😊🥳"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}